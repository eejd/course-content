{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "W2D1_Tutorial2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3710jvsc74a57bd03e19903e646247cead5404f55ff575624523d45cf244c3f93aaf5fa10367032a",
      "display_name": "Python 3.7.10 64-bit ('nma': conda)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eejd/course-content/blob/2021-bayes/tutorials/W2D1_BayesianStatistics/W2D1_Tutorial2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajm0vbDOa9tB"
      },
      "source": [
        "# Neuromatch Academy: Week 3, Day 1, Tutorial 2\n",
        "# Bayesian inference and decisions with continuous hidden state\n",
        "\n",
        "__Content creators:__ Eric DeWitt, Xaq Pitkow, Saeed Salehi, Ella Betty\n",
        "\n",
        "__Content reviewers:__ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISohim-Ta9tC"
      },
      "source": [
        "# Tutorial Objectives\n",
        "\n",
        "This notebook introduces you to Gaussians and Bayes' rule for continuous distributions, allowing us to model simple put powerful combinations of prior information and new measurements. In this notebook you will work through the same ideas we explored in the binary state tutorial, but you will be introduced to a new problem: finding and guiding Astrocat! You will see this problem again in more complex ways in the following days.\n",
        "\n",
        "In this notebook, you will:\n",
        "\n",
        "1. Learn about the Gaussian distribution and it's nice properies\n",
        "2. Explore how we can extend the ideas from the binary hidden tutorial to continuous distributions\n",
        "3. Explore how different priors can produce more complex posteriors.\n",
        "4. Explore Loss functions often used in inference and complex utility functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "eR8sfGi_a9tD"
      },
      "source": [
        "# @title Video 1: Introduction\n",
        "from IPython.display import YouTubeVideo\n",
        "video = YouTubeVideo(id='GdIwJWsW9-s', width=854, height=480, fs=1)\n",
        "print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "video"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video available at https://youtube.com/watch?v=GdIwJWsW9-s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.YouTubeVideo at 0x7fb3b1bad590>"
            ],
            "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://www.youtube.com/embed/GdIwJWsW9-s?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ",
            "image/jpeg": "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\n"
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upESZk9ga9tD"
      },
      "source": [
        "---\n",
        "##Setup  \n",
        "Please execute the cells below to initialize the notebook environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOzWD_Pga9tE"
      },
      "source": [
        "# imports\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.stats import multivariate_normal\n",
        "from scipy.stats import gamma as gamma_distribution\n",
        "from matplotlib.transforms import Affine2D"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "EBLHwDYla9tE"
      },
      "source": [
        "#@title Figure Settings\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import FloatSlider\n",
        "from ipywidgets import interact, fixed, HBox, Layout, VBox, interactive, Label\n",
        "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/nma.mplstyle\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmFeqjqa9tF"
      },
      "source": [
        "def gaussian(x, μ, σ):\n",
        "    return np.exp(-((x - μ) / σ)**2 / 2) / np.sqrt(2 * np.pi * σ**2)\n",
        "\n",
        "\n",
        "def gamma_pdf(x, α, β):\n",
        "    return gamma_distribution.pdf(x, a=α, scale=1/β)\n",
        "\n",
        "\n",
        "def mvn2d(x, y, mu1, mu2, sigma1, sigma2, cov12):\n",
        "    mvn = multivariate_normal([mu1, mu2], [[sigma1**2, cov12], [cov12, sigma2**2]])\n",
        "    return mvn.pdf(np.dstack((x, y)))\n",
        "\n",
        "\n",
        "def product_guassian(mu1, mu2, sigma1, sigma2):\n",
        "    J_1, J_2 = 1/sigma1**2, 1/sigma2**2\n",
        "    J_3 = J_1 + J_2\n",
        "    mu_prod = (J_1*mu1/J_3) + (J_2*mu2/J_3)\n",
        "    sigma_prod = np.sqrt(1/J_3)\n",
        "    return mu_prod, sigma_prod\n",
        "\n",
        "\n",
        "def reverse_product(mu3, sigma3, mu1, mu2):\n",
        "    J_3 = 1/sigma3**2\n",
        "    J_1 = J_3 * (mu3 - mu2) / (mu1 - mu2)\n",
        "    J_2 = J_3 * (mu3 - mu1) / (mu2 - mu1)\n",
        "    sigma1, sigma2 = 1/np.sqrt(J_1), 1/np.sqrt(J_2)\n",
        "    return sigma1, sigma2\n",
        "\n",
        "\n",
        "def calc_mean_mode_median(x, y):\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "    pdf = y * (x[1] - x[0])\n",
        "    # Calc mode of an arbitrary function\n",
        "    mode = x[np.argmax(pdf)]\n",
        "\n",
        "    # Calc mean of an arbitrary function\n",
        "    mean = np.multiply(x, pdf).sum()\n",
        "\n",
        "    # Calc median of an arbitrary function\n",
        "    cdf = np.cumsum(pdf)\n",
        "    idx = np.argmin(np.abs(cdf - 0.5))\n",
        "    median = x[idx]\n",
        "\n",
        "    return mean, median, mode\n",
        "\n",
        "\n",
        "def calc_loss_func(loss_f, mu_true, x):\n",
        "    error = x - mu_true\n",
        "    if loss_f == \"Mean Squared Error\":\n",
        "        loss = (error)**2\n",
        "    elif loss_f == \"Absolute Error\":\n",
        "        loss = np.abs(error)\n",
        "    elif loss_f == \"Zero-One Loss\":\n",
        "        loss = (np.abs(error) >= 0.03).astype(np.float)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calc_expected_loss(loss_f, posterior, x):\n",
        "    dx = x[1] - x[0]\n",
        "    expected_loss = np.zeros_like(x)\n",
        "    for i in np.arange(x.shape[0]):\n",
        "        loss = calc_loss_func(loss_f, x[i], x) # or mse or zero_one_loss\n",
        "        expected_loss[i] = np.sum(loss * posterior) * dx\n",
        "    return expected_loss\n",
        "\n",
        "\n",
        "def plot_gaussian(μ, σ):\n",
        "    x = np.linspace(-7, 7, 1000, endpoint=True)\n",
        "    y = gaussian(x, μ, σ)\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.plot(x, y, c='blue')\n",
        "    plt.fill_between(x, y, color='b', alpha=0.2)\n",
        "    plt.ylabel('$\\mathcal{N}(x, \\mu, \\sigma^2)$')\n",
        "    plt.xlabel('x')\n",
        "    plt.yticks([])\n",
        "    plt.show()\n",
        "\n",
        "def plot_losses(μ, σ):\n",
        "    x = np.linspace(-2, 2, 400, endpoint=True)\n",
        "    y = gaussian(x, μ, σ)\n",
        "    error = x - μ\n",
        "\n",
        "    mse_loss = (error)**2\n",
        "    abs_loss = np.abs(error)\n",
        "    zero_one_loss = (np.abs(error) >= 0.02).astype(np.float)\n",
        "\n",
        "    fig, (ax_gaus, ax_error) = plt.subplots(2, 1, figsize=(6, 8))\n",
        "    ax_gaus.plot(x, y, color='blue', label='true distribution')\n",
        "    ax_gaus.fill_between(x, y, color='blue', alpha=0.2)\n",
        "    ax_gaus.set_ylabel('$\\\\mathcal{N}(x, \\\\mu, \\\\sigma^2)$')\n",
        "    ax_gaus.set_xlabel('x')\n",
        "    ax_gaus.set_yticks([])\n",
        "    ax_gaus.legend(loc='upper right')\n",
        "\n",
        "    ax_error.plot(x, mse_loss, color='c', label='Mean Squared Error', linewidth=3)\n",
        "    ax_error.plot(x, abs_loss, color='m', label='Absolute Error', linewidth=3)\n",
        "    ax_error.plot(x, zero_one_loss, color='y', label='Zero-One Loss', linewidth=3)\n",
        "    ax_error.legend(loc='upper right')\n",
        "    ax_error.set_xlabel('$\\\\hat{\\\\mu}$')\n",
        "    ax_error.set_ylabel('Error')\n",
        "    plt.show()\n",
        "\n",
        "def plot_mvn2d(mu1, mu2, sigma1, sigma2, corr):\n",
        "    x, y = np.mgrid[-2:2:.02, -2:2:.02]\n",
        "    cov12 = corr * sigma1 * sigma2\n",
        "    z = mvn2d(x, y, mu1, mu2, sigma1, sigma2, cov12)\n",
        "\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.contourf(x, y, z, cmap='Reds')\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_marginal(sigma1, sigma2, c_x, c_y, corr):\n",
        "    mu1, mu2 = 0.0, 0.0\n",
        "    cov12 = corr * sigma1 * sigma2\n",
        "    xx, yy = np.mgrid[-2:2:.02, -2:2:.02]\n",
        "    x, y = xx[:, 0], yy[0]\n",
        "    p_x = gaussian(x, mu1, sigma1)\n",
        "    p_y = gaussian(y, mu2, sigma2)\n",
        "    zz = mvn2d(xx, yy, mu1, mu2, sigma1, sigma2, cov12)\n",
        "\n",
        "    mu_x_y = mu1+cov12*(c_y-mu2)/sigma2**2\n",
        "    mu_y_x = mu2+cov12*(c_x-mu1)/sigma1**2\n",
        "    sigma_x_y = np.sqrt(sigma2**2 - cov12**2/sigma1**2)\n",
        "    sigma_y_x = np.sqrt(sigma1**2-cov12**2/sigma2**2)\n",
        "    p_x_y = gaussian(x, mu_x_y, sigma_x_y)\n",
        "    p_y_x = gaussian(x, mu_y_x, sigma_y_x)\n",
        "\n",
        "    p_c_y = gaussian(mu_x_y-sigma_x_y, mu_x_y, sigma_x_y)\n",
        "    p_c_x = gaussian(mu_y_x-sigma_y_x, mu_y_x, sigma_y_x)\n",
        "\n",
        "    # definitions for the axes\n",
        "    left, width = 0.1, 0.65\n",
        "    bottom, height = 0.1, 0.65\n",
        "    spacing = 0.01\n",
        "\n",
        "    rect_z = [left, bottom, width, height]\n",
        "    rect_x = [left, bottom + height + spacing, width, 0.2]\n",
        "    rect_y = [left + width + spacing, bottom, 0.2, height]\n",
        "\n",
        "    # start with a square Figure\n",
        "    fig = plt.figure(figsize=(8, 8))\n",
        "\n",
        "    ax_z = fig.add_axes(rect_z)\n",
        "    ax_x = fig.add_axes(rect_x, sharex=ax_z)\n",
        "    ax_y = fig.add_axes(rect_y, sharey=ax_z)\n",
        "\n",
        "    ax_z.set_axis_off()\n",
        "    ax_x.set_axis_off()\n",
        "    ax_y.set_axis_off()\n",
        "    ax_x.set_xlim(np.min(x), np.max(x))\n",
        "    ax_y.set_ylim(np.min(y), np.max(y))\n",
        "\n",
        "    ax_z.contourf(xx, yy, zz, cmap='Greys')\n",
        "    ax_z.hlines(c_y, mu_x_y-sigma_x_y, mu_x_y+sigma_x_y, color='c', zorder=9, linewidth=3)\n",
        "    ax_z.vlines(c_x, mu_y_x-sigma_y_x, mu_y_x+sigma_y_x, color='m', zorder=9, linewidth=3)\n",
        "\n",
        "    ax_x.plot(x, p_x, label='$p(x)$', c = 'b', linewidth=3)\n",
        "    ax_x.plot(x, p_x_y, label='$p(x|y = C_y)$', c = 'c', linestyle='dashed', linewidth=3)\n",
        "    ax_x.hlines(p_c_y, mu_x_y-sigma_x_y, mu_x_y+sigma_x_y, color='c', linestyle='dashed', linewidth=3)\n",
        "\n",
        "    ax_y.plot(p_y, y, label='$p(y)$', c = 'r', linewidth=3)\n",
        "    ax_y.plot(p_y_x, y, label='$p(y|x = C_x)$', c = 'm', linestyle='dashed', linewidth=3)\n",
        "    ax_y.vlines(p_c_x, mu_y_x-sigma_y_x, mu_y_x+sigma_y_x, color='m', linestyle='dashed', linewidth=3)\n",
        "\n",
        "\n",
        "    ax_x.legend(loc=\"upper left\", frameon=False)\n",
        "    ax_y.legend(loc=\"lower right\", frameon=False)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_bayes(mu1, mu2, sigma1, sigma2):\n",
        "    x = np.linspace(-7, 7, 1000, endpoint=True)\n",
        "    prior = gaussian(x, mu1, sigma1)\n",
        "    likelihood = gaussian(x, mu2, sigma2)\n",
        "\n",
        "    mu_post, sigma_post = product_guassian(mu1, mu2, sigma1, sigma2)\n",
        "    posterior = gaussian(x, mu_post, sigma_post)\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(x, prior, c='b', label='prior')\n",
        "    plt.fill_between(x, prior, color='b', alpha=0.2)\n",
        "    plt.plot(x, likelihood, c='r', label='likelihood')\n",
        "    plt.fill_between(x, likelihood, color='r', alpha=0.2)\n",
        "    plt.plot(x, posterior, c='k', label='posterior')\n",
        "    plt.fill_between(x, posterior, color='k', alpha=0.2)\n",
        "    plt.yticks([])\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    plt.ylabel('$\\mathcal{N}(x, \\mu, \\sigma^2)$')\n",
        "    plt.xlabel('x')\n",
        "    plt.show()\n",
        "\n",
        "def plot_information(mu1, sigma1, mu2, sigma2):\n",
        "    x = np.linspace(-7, 7, 1000, endpoint=True)\n",
        "    mu3, sigma3 = product_guassian(mu1, mu2, sigma1, sigma2)\n",
        "    prior = gaussian(x, mu1, sigma1)\n",
        "    likelihood = gaussian(x, mu2, sigma2)\n",
        "    posterior = gaussian(x, mu3, sigma3)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(x, prior, c='b', label='Satellite')\n",
        "    plt.fill_between(x, prior, color='b', alpha=0.2)\n",
        "    plt.plot(x, likelihood, c='r', label='Space Mouse')\n",
        "    plt.fill_between(x, likelihood, color='r', alpha=0.2)\n",
        "    plt.plot(x, posterior, c='k', label='Center')\n",
        "    plt.fill_between(x, posterior, color='k', alpha=0.2)\n",
        "    plt.yticks([])\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    plt.ylabel('$\\mathcal{N}(x, \\mu, \\sigma^2)$')\n",
        "    plt.xlabel('x')\n",
        "    plt.show()\n",
        "\n",
        "def plot_information_global(mu3, sigma3, mu1, mu2):\n",
        "    x = np.linspace(-7, 7, 1000, endpoint=True)\n",
        "    sigma1, sigma2 = reverse_product(mu3, sigma3, mu1, mu2)\n",
        "    prior = gaussian(x, mu1, sigma1)\n",
        "    likelihood = gaussian(x, mu2, sigma2)\n",
        "    posterior = gaussian(x, mu3, sigma3)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(x, prior, c='b', label='Satellite')\n",
        "    plt.fill_between(x, prior, color='b', alpha=0.2)\n",
        "    plt.plot(x, likelihood, c='r', label='Space Mouse')\n",
        "    plt.fill_between(x, likelihood, color='r', alpha=0.2)\n",
        "    plt.plot(x, posterior, c='k', label='Center')\n",
        "    plt.fill_between(x, posterior, color='k', alpha=0.2)\n",
        "    plt.yticks([])\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    plt.ylabel('$\\mathcal{N}(x, \\mu, \\sigma^2)$')\n",
        "    plt.xlabel('x')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_loss_utility_gaussian(loss_f, mu, sigma, mu_true):\n",
        "    x = np.linspace(-7, 7, 1000, endpoint=True)\n",
        "    posterior = gaussian(x, mu, sigma)\n",
        "    mean, median, mode = mu, mu, mu\n",
        "\n",
        "    loss = calc_loss_func(loss_f, mu_true, x)\n",
        "\n",
        "    utility = - calc_expected_loss(loss_f, posterior, x)\n",
        "\n",
        "    plt.figure(figsize=(18, 5))\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.title(\"Probability\")\n",
        "    plt.plot(x, posterior, c='b')\n",
        "    plt.fill_between(x, posterior, color='b', alpha=0.2)\n",
        "    plt.yticks([])\n",
        "    plt.xlabel('x')\n",
        "    plt.ylabel('$\\mathcal{N}(x, \\mu, \\sigma^2)$')\n",
        "    plt.axvline(mean, ls='dashed', color='red', label='Mean')\n",
        "    plt.axvline(median, ls='dashdot', color='blue', label='Median')\n",
        "    plt.axvline(mode, ls='dotted', color='green', label='Mode')\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    \n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.title(loss_f)\n",
        "    plt.plot(x, loss, c='c', label=loss_f)\n",
        "    # plt.fill_between(x, loss, color='c', alpha=0.2)\n",
        "    plt.ylabel('loss')\n",
        "    # plt.legend(loc=\"upper left\")\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.title(\"Expected utility\")\n",
        "    plt.plot(x, utility, c='y', label='utility')\n",
        "    # plt.fill_between(x, utility, color='y', alpha=0.2)\n",
        "    plt.legend(loc=\"upper left\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_loss_utility_mixture(loss_f, mu1, mu2, sigma1, sigma2, factor, mu_true):\n",
        "\n",
        "    x = np.linspace(-7, 7, 1000, endpoint=True)\n",
        "    y_1 = gaussian(x, mu1, sigma1)\n",
        "    y_2 = gaussian(x, mu2, sigma2)\n",
        "\n",
        "    posterior = y_1 * factor + y_2 * (1.0 - factor)\n",
        "    \n",
        "    mean, median, mode = calc_mean_mode_median(x, posterior)\n",
        "\n",
        "    loss = calc_loss_func(loss_f, mu_true, x)\n",
        "\n",
        "    utility = - calc_expected_loss(loss_f, posterior, x)\n",
        "\n",
        "    plt.figure(figsize=(18, 5))\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.title(\"Probability\")\n",
        "    plt.plot(x, posterior, c='b')\n",
        "    plt.fill_between(x, posterior, color='b', alpha=0.2)\n",
        "    plt.yticks([])\n",
        "    plt.xlabel('x')\n",
        "    plt.ylabel('$\\pi \\cdot p(x) + (1-\\pi) \\cdot p(y)$')\n",
        "    plt.axvline(mean, ls='dashed', color='red', label='Mean')\n",
        "    plt.axvline(median, ls='dashdot', color='blue', label='Median')\n",
        "    plt.axvline(mode, ls='dotted', color='green', label='Mode')\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    \n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.title(loss_f)\n",
        "    plt.plot(x, loss, c='c', label=loss_f)\n",
        "    # plt.fill_between(x, loss, color='c', alpha=0.2)\n",
        "    plt.ylabel('loss')\n",
        "    # plt.legend(loc=\"upper left\")\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.title(\"Expected utility\")\n",
        "    plt.plot(x, utility, c='y', label='utility')\n",
        "    # plt.fill_between(x, utility, color='y', alpha=0.2)\n",
        "    plt.legend(loc=\"upper left\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_loss_utility_bayes(mu1, mu2, sigma1, sigma2, mu_true, loss_f):\n",
        "    x = np.linspace(-4, 4, 1000, endpoint=True)\n",
        "\n",
        "    prior = gaussian(x, mu1, sigma1)\n",
        "    likelihood = gaussian(x, mu2, sigma2)\n",
        "\n",
        "    mu_post, sigma_post = product_guassian(mu1, mu2, sigma1, sigma2)\n",
        "    posterior = gaussian(x, mu_post, sigma_post)\n",
        "\n",
        "    loss = calc_loss_func(loss_f, mu_true, x)\n",
        "\n",
        "    utility = - calc_expected_loss(loss_f, posterior, x)\n",
        "\n",
        "    plt.figure(figsize=(18, 5))\n",
        "    plt.subplot(1, 3, 1)\n",
        "\n",
        "    plt.title(\"Posterior distribution\")\n",
        "    plt.plot(x, prior, c='b', label='prior')\n",
        "    plt.fill_between(x, prior, color='b', alpha=0.2)\n",
        "    plt.plot(x, likelihood, c='r', label='likelihood')\n",
        "    plt.fill_between(x, likelihood, color='r', alpha=0.2)\n",
        "    plt.plot(x, posterior, c='k', label='posterior')\n",
        "    plt.fill_between(x, posterior, color='k', alpha=0.2)\n",
        "    plt.yticks([])\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    # plt.ylabel('$f(x)$')\n",
        "    plt.xlabel('x')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.title(loss_f)\n",
        "    plt.plot(x, loss, c='c')\n",
        "    # plt.fill_between(x, loss, color='c', alpha=0.2)\n",
        "    plt.ylabel('loss')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.title(\"Expected utility\")\n",
        "    plt.plot(x, utility, c='y', label='utility')\n",
        "    # plt.fill_between(x, utility, color='y', alpha=0.2)\n",
        "    plt.legend(loc=\"upper left\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_simple_utility_gaussian(mu, sigma, mu_g, mu_c, sigma_g, sigma_c):\n",
        "    x = np.linspace(-7, 7, 1000, endpoint=True)\n",
        "    posterior = gaussian(x, mu, sigma)\n",
        "    gain = gaussian(x, mu_g, sigma_g)\n",
        "    loss = gaussian(x, mu_c, sigma_c)\n",
        "    utility = np.multiply(posterior, gain) - np.multiply(posterior, loss)\n",
        "\n",
        "    plt.figure(figsize=(18, 5))\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.title(\"Probability\")\n",
        "    plt.plot(x, posterior, c='b', label='posterior')\n",
        "    plt.fill_between(x, posterior, color='b', alpha=0.2)\n",
        "    plt.yticks([])\n",
        "    # plt.legend(loc=\"upper left\")\n",
        "    plt.xlabel('x')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.title(\"utility function\")\n",
        "    plt.plot(x, gain, c='m', label='gain')\n",
        "    # plt.fill_between(x, gain, color='m', alpha=0.2)\n",
        "    plt.plot(x, -loss, c='c', label='loss')\n",
        "    # plt.fill_between(x, -loss, color='c', alpha=0.2)\n",
        "    plt.legend(loc=\"upper left\")\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.title(\"expected utility\")\n",
        "    plt.plot(x, utility, c='y', label='utility')\n",
        "    # plt.fill_between(x, utility, color='y', alpha=0.2)\n",
        "    plt.legend(loc=\"upper left\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_utility_gaussian(mu1, mu2, sigma1, sigma2, mu_g, mu_c, sigma_g, sigma_c):\n",
        "    x = np.linspace(-7, 7, 1000, endpoint=True)\n",
        "    prior = gaussian(x, mu1, sigma1)\n",
        "    likelihood = gaussian(x, mu2, sigma2)\n",
        "    gain = gaussian(x, mu_g, sigma_g)\n",
        "    loss = gaussian(x, mu_c, sigma_c)\n",
        "\n",
        "    mu_post, sigma_post = product_guassian(mu1, mu2, sigma1, sigma2)\n",
        "    posterior = gaussian(x, mu_post, sigma_post)\n",
        "\n",
        "    utility = np.multiply(posterior, gain) - np.multiply(posterior, loss)\n",
        "\n",
        "    plot_utility(x, prior, likelihood, posterior, gain, loss, utility)\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def plot_utility_mixture(mu_m1, mu_m2, sigma_m1, sigma_m2, factor,\n",
        "                         mu, sigma, mu_g, mu_c, sigma_g, sigma_c):\n",
        "    x = np.linspace(-7, 7, 1000, endpoint=True)\n",
        "    y_1 = gaussian(x, mu_m1, sigma_m1)\n",
        "    y_2 = gaussian(x, mu_m2, sigma_m2)\n",
        "    prior = y_1 * factor + y_2 * (1.0 - factor)\n",
        "\n",
        "    likelihood = gaussian(x, mu, sigma)\n",
        "    gain = gaussian(x, mu_g, sigma_g)\n",
        "    loss = gaussian(x, mu_c, sigma_c)\n",
        "\n",
        "    posterior = np.multiply(prior, likelihood)\n",
        "    posterior = posterior / (posterior.sum() * (x[1] - x[0]))\n",
        "\n",
        "    utility = np.multiply(posterior, gain) - np.multiply(posterior, loss)\n",
        "\n",
        "    plot_utility(x, prior, likelihood, posterior, gain, loss, utility)\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def plot_utility_uniform(mu, sigma, mu_g, mu_c, sigma_g, sigma_c):\n",
        "    x = np.linspace(-7, 7, 1000, endpoint=True)\n",
        "    prior = np.ones_like(x) / (x.max() - x.min())\n",
        "    likelihood = gaussian(x, mu, sigma)\n",
        "    gain = gaussian(x, mu_g, sigma_g)\n",
        "    loss = gaussian(x, mu_c, sigma_c)\n",
        "\n",
        "    posterior = likelihood\n",
        "    # posterior = np.multiply(prior, likelihood)\n",
        "    # posterior = posterior / (posterior.sum() * (x[1] - x[0]))\n",
        "\n",
        "    utility = np.multiply(posterior, gain) - np.multiply(posterior, loss)\n",
        "\n",
        "    plot_utility(x, prior, likelihood, posterior, gain, loss, utility)\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def plot_utility_gamma(alpha, beta, offset, mu, sigma, mu_g, mu_c, sigma_g, sigma_c):\n",
        "    x = np.linspace(-7, 7, 1000, endpoint=True)\n",
        "    prior = gamma_pdf(x-offset, alpha, beta)\n",
        "    likelihood = gaussian(x, mu, sigma)\n",
        "    gain = gaussian(x, mu_g, sigma_g)\n",
        "    loss = gaussian(x, mu_c, sigma_c)\n",
        "\n",
        "    posterior = np.multiply(prior, likelihood)\n",
        "    posterior = posterior / (posterior.sum() * (x[1] - x[0]))\n",
        "\n",
        "    utility = np.multiply(posterior, gain) - np.multiply(posterior, loss)\n",
        "\n",
        "    plot_utility(x, prior, likelihood, posterior, gain, loss, utility)\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def plot_utility(x, prior, likelihood, posterior, gain, loss, utility):\n",
        "    plt.figure(figsize=(18, 5))\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.title(\"Posterior distribution\")\n",
        "    plt.plot(x, prior, c='b', label='prior')\n",
        "    plt.fill_between(x, prior, color='b', alpha=0.2)\n",
        "    plt.plot(x, likelihood, c='r', label='likelihood')\n",
        "    plt.fill_between(x, likelihood, color='r', alpha=0.2)\n",
        "    plt.plot(x, posterior, c='k', label='posterior')\n",
        "    plt.fill_between(x, posterior, color='k', alpha=0.2)\n",
        "    plt.yticks([])\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    # plt.ylabel('$f(x)$')\n",
        "    plt.xlabel('x')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.title(\"utility function\")\n",
        "    plt.plot(x, gain, c='m', label='gain')\n",
        "    # plt.fill_between(x, gain, color='m', alpha=0.2)\n",
        "    plt.plot(x, -loss, c='c', label='loss')\n",
        "    # plt.fill_between(x, -loss, color='c', alpha=0.2)\n",
        "    plt.legend(loc=\"upper left\")\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.title(\"expected utility\")\n",
        "    plt.plot(x, utility, c='y', label='utility')\n",
        "    # plt.fill_between(x, utility, color='y', alpha=0.2)\n",
        "    plt.legend(loc=\"upper left\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def gaussian_mixture(mu1, mu2, sigma1, sigma2, factor):\n",
        "    assert 0.0 < factor < 1.0\n",
        "    x = np.linspace(-7.0, 7.0, 1000, endpoint=True)\n",
        "    y_1 = gaussian(x, mu1, sigma1)\n",
        "    y_2 = gaussian(x, mu2, sigma2)\n",
        "    mixture = y_1 * factor + y_2 * (1.0 - factor)\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(x, y_1, c='deepskyblue', label='p(x)', linewidth=3.0)\n",
        "    plt.fill_between(x, y_1, color='deepskyblue', alpha=0.2)\n",
        "    plt.plot(x, y_2, c='aquamarine', label='p(y)', linewidth=3.0)\n",
        "    plt.fill_between(x, y_2, color='aquamarine', alpha=0.2)\n",
        "    plt.plot(x, mixture, c='b', label='$\\pi \\cdot p(x) + (1-\\pi) \\cdot p(y)$',  linewidth=3.0)\n",
        "    plt.fill_between(x, mixture, color='b', alpha=0.2)\n",
        "    plt.yticks([])\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    # plt.ylabel('$f(x)$')\n",
        "    plt.xlabel('x')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_bayes_loss_utility_gaussian(loss_f, mu_true, mu1, mu2, sigma1, sigma2):\n",
        "    x = np.linspace(-7, 7, 1000, endpoint=True)\n",
        "\n",
        "    prior = gaussian(x, mu1, sigma1)\n",
        "    likelihood = gaussian(x, mu2, sigma2)\n",
        "    mu_post, sigma_post = product_guassian(mu1, mu2, sigma1, sigma2)\n",
        "    posterior = gaussian(x, mu_post, sigma_post)\n",
        "\n",
        "    loss = calc_loss_func(loss_f, mu_true, x)\n",
        "\n",
        "    plot_bayes_loss_utility(x, prior, likelihood, posterior, loss, loss_f)\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def plot_bayes_loss_utility_uniform(loss_f, mu_true, mu, sigma):\n",
        "    x = np.linspace(-7, 7, 1000, endpoint=True)\n",
        "\n",
        "    prior = np.ones_like(x) / (x.max() - x.min())\n",
        "    likelihood = gaussian(x, mu, sigma)\n",
        "    posterior = likelihood\n",
        "\n",
        "    loss = calc_loss_func(loss_f, mu_true, x)\n",
        "\n",
        "    plot_bayes_loss_utility(x, prior, likelihood, posterior, loss, loss_f)\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def plot_bayes_loss_utility_gamma(loss_f, mu_true, alpha, beta, offset, mu, sigma):\n",
        "    x = np.linspace(-7, 7, 1000, endpoint=True)\n",
        "    prior = gamma_pdf(x-offset, alpha, beta)\n",
        "    likelihood = gaussian(x, mu, sigma)\n",
        "    posterior = np.multiply(prior, likelihood)\n",
        "    posterior = posterior / (posterior.sum() * (x[1] - x[0]))\n",
        "\n",
        "    loss = calc_loss_func(loss_f, mu_true, x)\n",
        "\n",
        "    plot_bayes_loss_utility(x, prior, likelihood, posterior, loss, loss_f)\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def plot_bayes_loss_utility_mixture(loss_f, mu_true, mu_m1, mu_m2, sigma_m1, sigma_m2, factor, mu, sigma):\n",
        "    x = np.linspace(-7, 7, 1000, endpoint=True)\n",
        "    y_1 = gaussian(x, mu_m1, sigma_m1)\n",
        "    y_2 = gaussian(x, mu_m2, sigma_m2)\n",
        "    prior = y_1 * factor + y_2 * (1.0 - factor)\n",
        "    likelihood = gaussian(x, mu, sigma)\n",
        "\n",
        "    posterior = np.multiply(prior, likelihood)\n",
        "    posterior = posterior / (posterior.sum() * (x[1] - x[0]))\n",
        "\n",
        "    loss = calc_loss_func(loss_f, mu_true, x)\n",
        "\n",
        "    plot_bayes_loss_utility(x, prior, likelihood, posterior, loss, loss_f)\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def plot_bayes_loss_utility(x, prior, likelihood, posterior, loss, loss_f):\n",
        "    plt.figure(figsize=(18, 3.5))\n",
        "\n",
        "    plt.subplot(1, 4, 1)\n",
        "    plt.title(\"Prior and Likelihood\")\n",
        "    plt.plot(x, prior, c='b', label='prior')\n",
        "    plt.fill_between(x, prior, color='b', alpha=0.2)\n",
        "    plt.plot(x, likelihood, c='r', label='likelihood')\n",
        "    plt.fill_between(x, likelihood, color='r', alpha=0.2)\n",
        "    plt.yticks([])\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    plt.xlabel('x')\n",
        "\n",
        "    plt.subplot(1, 4, 2)\n",
        "    plt.title(\"Posterior\")\n",
        "    plt.plot(x, posterior, c='k', label='posterior')\n",
        "    plt.fill_between(x, posterior, color='k', alpha=0.1)\n",
        "\n",
        "    mean, median, mode = calc_mean_mode_median(x, posterior)\n",
        "    plt.axvline(mean, ls='dashed', color='red', label='Mean')\n",
        "    plt.axvline(median, ls='dashdot', color='blue', label='Median')\n",
        "    plt.axvline(mode, ls='dotted', color='green', label='Mode')\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    plt.yticks([])\n",
        "\n",
        "    plt.subplot(1, 4, 3)\n",
        "    plt.title(loss_f)\n",
        "    plt.plot(x, loss, c='c', label=loss_f)\n",
        "    # plt.fill_between(x, loss, color='c', alpha=0.2)\n",
        "    plt.ylabel('loss')\n",
        "\n",
        "    plt.subplot(1, 4, 4)\n",
        "    expected_loss = calc_expected_loss(loss_f, posterior, x)\n",
        "    min_expected_loss = x[np.argmin(expected_loss)]\n",
        "    plt.title(\"expected loss\")\n",
        "    plt.plot(x, expected_loss, c='y', label='expected loss')\n",
        "    # plt.fill_between(x, expected_loss, color='y', alpha=0.2)\n",
        "    plt.axvline(min_expected_loss, ls='dashed', color='red', label='$Min~ \\mathbb{E}[Loss]$')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def loss_plot_switcher(what_to_plot):\n",
        "    if what_to_plot == \"Gaussian\":\n",
        "        widget = interact(plot_loss_utility_gaussian,\n",
        "            loss_f = widgets.Dropdown(\n",
        "                options=[\"Mean Squared Error\", \"Absolute Error\", \"Zero-One Loss\"], \n",
        "                value=\"Mean Squared Error\", description=\"Loss: \"),\n",
        "            mu = FloatSlider(min=-4.0, max=4.0, step=0.01, value=-0.5, description=\"µ_estimate\", continuous_update=False),\n",
        "            sigma = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_estimate\", continuous_update=False),\n",
        "            mu_true = FloatSlider(min=-3.0, max=3.0, step=0.01, value=0.0, description=\"µ_true\", continuous_update=False))\n",
        "    elif what_to_plot == \"Mixture of Gaussians\":\n",
        "        widget = interact(plot_loss_utility_mixture,\n",
        "            mu1 = FloatSlider(min=-4.0, max=4.0, step=0.01, value=-0.5, description=\"µ_est_1\", continuous_update=False),\n",
        "            mu2 = FloatSlider(min=-4.0, max=4.0, step=0.01, value=-0.5, description=\"µ_est_2\", continuous_update=False),\n",
        "            sigma1 = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_est_1\", continuous_update=False),\n",
        "            sigma2 = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_est_2\", continuous_update=False),\n",
        "            factor = FloatSlider(min=0.0, max=1.0, step=0.01, value=0.5, description=\"π\", continuous_update=False),\n",
        "            mu_true = FloatSlider(min=-3.0, max=3.0, step=0.01, value=0.0, description=\"µ_true\", continuous_update=False),\n",
        "            loss_f = widgets.Dropdown(\n",
        "                options=[\"Mean Squared Error\", \"Absolute Error\", \"Zero-One Loss\"], \n",
        "                value=\"Mean Squared Error\", description=\"Loss: \"))\n",
        "\n",
        "\n",
        "def plot_prior_switcher(what_to_plot):\n",
        "    if what_to_plot == \"Gaussian\":\n",
        "        widget = interact(plot_utility_gaussian,\n",
        "                  mu1 = FloatSlider(min=-4.0, max=4.0, step=0.01, value=-0.5, description=\"µ_prior\", continuous_update=False),\n",
        "                  mu2 = FloatSlider(min=-4.0, max=4.0, step=0.01, value=0.5, description=\"µ_likelihood\", continuous_update=False),\n",
        "                  sigma1 = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_prior\", continuous_update=False),\n",
        "                  sigma2 = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_likelihood\", continuous_update=False),\n",
        "                  mu_g = FloatSlider(min=-4.0, max=4.0, step=0.01, value=1.0, description=\"µ_gain\", continuous_update=False),\n",
        "                  mu_c = FloatSlider(min=-4.0, max=4.0, step=0.01, value=-1.0, description=\"µ_cost\", continuous_update=False),\n",
        "                  sigma_g = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_gain\", continuous_update=False),\n",
        "                  sigma_c = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_cost\", continuous_update=False))\n",
        "    elif what_to_plot == \"Uniform\":\n",
        "        widget = interact(plot_utility_uniform,\n",
        "                  mu = FloatSlider(min=-4.0, max=4.0, step=0.01, value=0.5, description=\"µ_likelihood\", continuous_update=False),\n",
        "                  sigma = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_likelihood\", continuous_update=False),\n",
        "                  mu_g = FloatSlider(min=-4.0, max=4.0, step=0.01, value=1.0, description=\"µ_gain\", continuous_update=False),\n",
        "                  mu_c = FloatSlider(min=-4.0, max=4.0, step=0.01, value=-1.0, description=\"µ_cost\", continuous_update=False),\n",
        "                  sigma_g = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_gain\", continuous_update=False),\n",
        "                  sigma_c = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_cost\", continuous_update=False))\n",
        "    elif what_to_plot == \"Gamma\":\n",
        "        widget = interact(plot_utility_gamma,\n",
        "                  alpha = FloatSlider(min=1.0, max=10.0, step=0.1, value=2.0, description=\"α_prior\", continuous_update=False),\n",
        "                  beta = FloatSlider(min=0.5, max=2.0, step=0.01, value=1.0, description=\"β_prior\", continuous_update=False),\n",
        "                  offset = FloatSlider(min=-6.0, max=2.0, step=0.1, value=0.0, description=\"offset\", continuous_update=False),\n",
        "                  mu = FloatSlider(min=-4.0, max=4.0, step=0.01, value=0.5, description=\"µ_likelihood\", continuous_update=False),\n",
        "                  sigma = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_likelihood\", continuous_update=False),\n",
        "                  mu_g = FloatSlider(min=-4.0, max=4.0, step=0.01, value=1.0, description=\"µ_gain\", continuous_update=False),\n",
        "                  mu_c = FloatSlider(min=-4.0, max=4.0, step=0.01, value=-1.0, description=\"µ_cost\", continuous_update=False),\n",
        "                  sigma_g = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_gain\", continuous_update=False),\n",
        "                  sigma_c = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_cost\", continuous_update=False))\n",
        "    elif what_to_plot == \"Mixture of Gaussians\":\n",
        "        widget = interact(plot_utility_mixture,\n",
        "                  mu_m1 = FloatSlider(min=-4.0, max=4.0, step=0.01, value=-0.5, description=\"µ_mix_1\", continuous_update=False),\n",
        "                  mu_m2 = FloatSlider(min=-4.0, max=4.0, step=0.01, value=0.5, description=\"µ_mix_1\", continuous_update=False),\n",
        "                  sigma_m1 = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_mix_1\", continuous_update=False),\n",
        "                  sigma_m2 = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_mix_2\", continuous_update=False),\n",
        "                  factor = FloatSlider(min=0.0, max=1.0, step=0.01, value=0.5, description=\"π\", continuous_update=False),\n",
        "                  mu = FloatSlider(min=-4.0, max=4.0, step=0.01, value=0.5, description=\"µ_likelihood\", continuous_update=False),\n",
        "                  sigma = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_likelihood\", continuous_update=False),\n",
        "                  mu_g = FloatSlider(min=-4.0, max=4.0, step=0.01, value=1.0, description=\"µ_gain\", continuous_update=False),\n",
        "                  mu_c = FloatSlider(min=-4.0, max=4.0, step=0.01, value=-1.0, description=\"µ_cost\", continuous_update=False),\n",
        "                  sigma_g = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_gain\", continuous_update=False),\n",
        "                  sigma_c = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_cost\", continuous_update=False))\n",
        "        \n",
        "def plot_bayes_loss_utility_switcher(what_to_plot):\n",
        "    if what_to_plot == \"Gaussian\":\n",
        "        widget = interact(plot_bayes_loss_utility_gaussian,\n",
        "                  mu1 = FloatSlider(min=-4.0, max=4.0, step=0.01, value=-0.5, description=\"µ_prior\", continuous_update=False),\n",
        "                  mu2 = FloatSlider(min=-4.0, max=4.0, step=0.01, value=0.5, description=\"µ_likelihood\", continuous_update=False),\n",
        "                  sigma1 = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_prior\", continuous_update=False),\n",
        "                  sigma2 = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_likelihood\", continuous_update=False),\n",
        "                  mu_true = FloatSlider(min=-4.0, max=4.0, step=0.01, value=-0.5, description=\"µ_true\", continuous_update=False),\n",
        "                  loss_f = widgets.Dropdown(\n",
        "                      options=[\"Mean Squared Error\", \"Absolute Error\", \"Zero-One Loss\"], \n",
        "                      value=\"Mean Squared Error\", description=\"Loss: \"))\n",
        "    elif what_to_plot == \"Uniform\":\n",
        "        widget = interact(plot_bayes_loss_utility_uniform,\n",
        "                  mu = FloatSlider(min=-4.0, max=4.0, step=0.01, value=0.5, description=\"µ_likelihood\", continuous_update=False),\n",
        "                  sigma = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_likelihood\", continuous_update=False),\n",
        "                  mu_true = FloatSlider(min=-4.0, max=4.0, step=0.01, value=-0.5, description=\"µ_true\", continuous_update=False),\n",
        "                  loss_f = widgets.Dropdown(\n",
        "                      options=[\"Mean Squared Error\", \"Absolute Error\", \"Zero-One Loss\"], \n",
        "                      value=\"Mean Squared Error\", description=\"Loss: \"))\n",
        "    elif what_to_plot == \"Gamma\":\n",
        "        widget = interact(plot_bayes_loss_utility_gamma,\n",
        "                  alpha = FloatSlider(min=1.0, max=10.0, step=0.1, value=2.0, description=\"α_prior\", continuous_update=False),\n",
        "                  beta = FloatSlider(min=0.5, max=2.0, step=0.01, value=1.0, description=\"β_prior\", continuous_update=False),\n",
        "                  offset = FloatSlider(min=-6.0, max=2.0, step=0.1, value=0.0, description=\"offset\", continuous_update=False),\n",
        "                  mu = FloatSlider(min=-4.0, max=4.0, step=0.01, value=0.5, description=\"µ_likelihood\", continuous_update=False),\n",
        "                  sigma = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_likelihood\", continuous_update=False),\n",
        "                  mu_true = FloatSlider(min=-4.0, max=4.0, step=0.01, value=-0.5, description=\"µ_true\", continuous_update=False),\n",
        "                  loss_f = widgets.Dropdown(\n",
        "                      options=[\"Mean Squared Error\", \"Absolute Error\", \"Zero-One Loss\"], \n",
        "                      value=\"Mean Squared Error\", description=\"Loss: \"))\n",
        "    elif what_to_plot == \"Mixture of Gaussians\":\n",
        "        widget = interact(plot_bayes_loss_utility_mixture,\n",
        "                  mu_m1 = FloatSlider(min=-4.0, max=4.0, step=0.01, value=-0.5, description=\"µ_mix_1\", continuous_update=False),\n",
        "                  mu_m2 = FloatSlider(min=-4.0, max=4.0, step=0.01, value=0.5, description=\"µ_mix_1\", continuous_update=False),\n",
        "                  sigma_m1 = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_mix_1\", continuous_update=False),\n",
        "                  sigma_m2 = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_mix_2\", continuous_update=False),\n",
        "                  factor = FloatSlider(min=0.0, max=1.0, step=0.01, value=0.5, description=\"π\", continuous_update=False),\n",
        "                  mu = FloatSlider(min=-4.0, max=4.0, step=0.01, value=0.5, description=\"µ_likelihood\", continuous_update=False),\n",
        "                  sigma = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_likelihood\", continuous_update=False),\n",
        "                  mu_true = FloatSlider(min=-4.0, max=4.0, step=0.01, value=-0.5, description=\"µ_true\", continuous_update=False),\n",
        "                  loss_f = widgets.Dropdown(\n",
        "                      options=[\"Mean Squared Error\", \"Absolute Error\", \"Zero-One Loss\"], \n",
        "                      value=\"Mean Squared Error\", description=\"Loss: \"))\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AILoNnT-a9tH"
      },
      "source": [
        "# @title Video 2: Astrocat!\n",
        "from IPython.display import YouTubeVideo\n",
        "# video = YouTubeVideo(id='GdIwJWsW9-s', width=854, height=480, fs=1)\n",
        "# print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "# video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4N2Qr7ra9tH"
      },
      "source": [
        "# Section 1: Likelihoods and utility - continuous distributions\n",
        "\n",
        "## Estimation: Astrocat's location and noisy estimates\n",
        "\n",
        "Now that you have been introduced to Astrocat, we need to extend the ideas from tutorial 1. We are going to think first about how Ground Control should estimate his position. We won't consider measurements yet, just how to represent the uncertainty we might have in general, and how to think about the way we should combine possible gains or losses when we make an estimate.\n",
        "\n",
        "Remember, in this example, you can think of yourself as a scientist trying to decide where we belive Astrocat is, how to select a point estimate based on possible errors, and how to account for the unvertainty we have about the locaiton of the satellite and the space mouse. In fact, this is the kind of problem real scientists working to control remote satellites face! However, we can also think of this as what your brain has does when it wants to determine a target to make a movement or hit a tennis ball! A number of classic experiments use this kind of framing to study how *optimal* human decisions or movements are! Some examples are in the reading.\n",
        "\n",
        "The important concepts intoduced in this section are:\n",
        "\n",
        "1. The Gaussian distribution\n",
        "2. Multiplying Gaussians and relative information\n",
        "3. Mixtures of Gaussians\n",
        "4. The use of Loss functions in estimatio\n",
        "5. The use of Utility functions to describe the gains and loses for taking an action"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U7Ci7Foa9tI"
      },
      "source": [
        "# @title Video 3: Likelihoods and utility - continuous distributions\n",
        "from IPython.display import YouTubeVideo\n",
        "# video = YouTubeVideo(id='GdIwJWsW9-s', width=854, height=480, fs=1)\n",
        "# print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "# video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGKqnqANa9tI"
      },
      "source": [
        "## The Gaussian Distribution\n",
        "\n",
        "We know the Bayesian approach can be used on any probability distribution. Although many things in the world require representation using complex or unknown (e.g. emperical) distributions, the Gaussian distribution is special. Because of the Central Limit Theorem, many quantities are Gaussian--or *normally distributed*--or measurements on them are Gaussian. Gaussians also have some mathematical properties that permit simple closed-form solutions to several important problems. And we can use *mixtures* of Gaussians to approximate other distributions. In short, the Gaussian is probably the most important continous distribution to understand and use.\n",
        "\n",
        "?? if we implement \n",
        "\n",
        "### Exercise 1:\n",
        "First, you will implement a Gaussian by filling in the missing portion of `my_gaussian` below. Gaussians have two parameters. The **mean** $\\mu$, which sets the location of its center. Its \"scale\" or spread is controlled by its **standard deviation** $\\sigma$ or its square, the **variance** $\\sigma^2$. (Be careful not to use one when the other is required). \n",
        "\n",
        "The equation for a Gaussian is:\n",
        "$$\n",
        "\\mathcal{N}(\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(\\frac{-(x-\\mu)^2}{2\\sigma^2}\\right)\n",
        "$$\n",
        "Also, don't forget that this is a probability distribution and should therefore sum to one. While this happens \"automatically\" when integrated from $-\\infty$ to $\\infty$, your version will only be computed over a finite number of points. You therefore need to explicitly normalize it yourself.\n",
        "\n",
        "Test out your implementation with a $\\mu = -1$ and $\\sigma = 1$. After you have it working, play with the  parameters to develop an intuition for how changing $\\mu$ and $\\sigma$ alter the shape of the Gaussian. This is important, because subsequent exercises will be built out of Gaussians. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "N_qgI8rza9tG"
      },
      "source": [
        "#@title Helper functions\n",
        "# --- maybe we allow them to implement gaussian and cost?\n",
        "def my_gaussian(x_points, mu, sigma):\n",
        "    \"\"\"\n",
        "    DO NOT EDIT THIS FUNCTION !!!\n",
        "\n",
        "    Returns normalized Gaussian estimated at points `x_points`, with parameters `mu` and `sigma`\n",
        "\n",
        "    Args:\n",
        "      x_points (numpy array of floats) - points at which the gaussian is evaluated\n",
        "      mu (scalar) - mean of the Gaussian\n",
        "      sigma (scalar) - standard deviation of the gaussian\n",
        "    Returns:\n",
        "      (numpy array of floats): normalized Gaussian (i.e. without constant) evaluated at `x`\n",
        "    \"\"\"\n",
        "    px = np.exp(- 1/2/sigma**2 * (mu - x_points) ** 2)\n",
        "\n",
        "    px = px / px.sum() # this is the normalization part with a very strong assumption, that\n",
        "                       # x_points cover the big portion of probability mass around the mean.\n",
        "                       # Please think/discuss when this would be a dangerous assumption.\n",
        "\n",
        "    return px\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLlFK11La9tI"
      },
      "source": [
        "?? if we have them code the gaussian, it goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmitvcV6a9tJ"
      },
      "source": [
        "### Exercise 2:\n",
        "\n",
        "Play with the Gaussian you made. Remember that we explained that the information (about the mean, $\\mu$) is $\\frac{1}{\\sigma^2}$.\n",
        "\n",
        "1. If you wanted to know the probabilty of an event happing at $0$, can you find two different $\\mu$ and $\\sigma$ values that produce the same probabilty of an event at $0$?\n",
        "2. How many Gaussian's could produce the same probabilty at $0$?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OI1jBhLa9tJ"
      },
      "source": [
        "widget = interact(plot_gaussian,\n",
        "                     μ = FloatSlider(min=-4.0, max=4.0, step=0.01, value=0.0, continuous_update=False),\n",
        "                     σ = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, continuous_update=False))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAFMx5nMa9tK"
      },
      "source": [
        "## Mixture's of Gaussians - interactive demo\n",
        "\n",
        "We can also combine Gaussian's using the idea of a *mixture distribution*. In a Gaussian mixture distribution, you use a random variable to draw from each of the the Guassian's you are mixing! We will not cover the derivation here but you can work it out as a bonux exercise!\n",
        "\n",
        "Mixture distributions are useful if you want to represent a multi-model distribution (i.e. where the distribution isn't goes up and down more than once). They are a common tool in Bayesian modeling and an important tool in general.\n",
        "\n",
        "Use the following widget to experiment with the parameters of each Gaussian and the mixing weight ($\\pi$) to undersand how the mixture of Gaussian distribution behaves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# if we have them code this, it goes here\n",
        "\n",
        "def plot_mixture_prior(x, gaussian1, gaussian2, combined):\n",
        "    \"\"\"\n",
        "    DO NOT EDIT THIS FUNCTION !!!\n",
        "\n",
        "    Plots a prior made of a mixture of gaussians\n",
        "\n",
        "    Args:\n",
        "      x (numpy array of floats):         points at which the likelihood has been evaluated\n",
        "      gaussian1 (numpy array of floats): normalized probabilities for Gaussian 1 evaluated at each `x`\n",
        "      gaussian2 (numpy array of floats): normalized probabilities for Gaussian 2 evaluated at each `x`\n",
        "      posterior (numpy array of floats): normalized probabilities for the posterior evaluated at each `x`\n",
        "\n",
        "    Returns:\n",
        "      Nothing\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(x, gaussian1, '--b', LineWidth=2, label='Gaussian 1')\n",
        "    ax.plot(x, gaussian2, '-.b', LineWidth=2, label='Gaussian 2')\n",
        "    ax.plot(x, combined, '-r', LineWidth=2, label='Gaussian Mixture')\n",
        "    ax.legend()\n",
        "    ax.set_ylabel('Probability')\n",
        "    ax.set_xlabel('Orientation (Degrees)')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoUoeB5Ka9tL"
      },
      "source": [
        "widget = interact(gaussian_mixture,\n",
        "            mu1 = FloatSlider(min=-4.0, max=4.0, step=0.01, value=1.0, description=\"µ_1\", continuous_update=False),\n",
        "            mu2 = FloatSlider(min=-4.0, max=4.0, step=0.01, value=-1.0, description=\"µ_2\", continuous_update=False),\n",
        "            sigma1 = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_1\", continuous_update=False),\n",
        "            sigma2 = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_2\", continuous_update=False),\n",
        "            factor = FloatSlider(min=0.1, max=0.9, step=0.01, value=0.5, description=\"π\", continuous_update=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnYT7EA2a9tL"
      },
      "source": [
        "## Utility functions: Loss functions\n",
        "\n",
        "A utility function, as we have seen, represents a gain or loss (also called a cost). When we are asked for a single estimate from a probability distribution, we are explicitly or implicitly defining a specifc utility function--the *Loss* associated with being 'wrong' in our 'choice' with respect to the probabilities. Think about our case, we want to know where Astrocat is. If we were asked to provide the coordinates, for example to display them for Ground Control or two note them in a log, we are not going to provide the whole probability distribution! So, we use an estimator or, equivilantly, we define a Loss function. We are going to explore this for the Gaussian distribution, where our estimate is $\\hat{\\mu}$ and the true hidden state we are interested in is $\\mu$. ?? could extend to mixture ??\n",
        "\n",
        "A Loss function determines the \"cost\" (or penalty) of estimating $\\hat \\mu$ when the true or correct quantity is really $\\mu$ (this is essentially the cost of the error between the true hidden state we are interested in: $\\mu$ and our estimate: $\\hat \\mu$ -- Note that the error can be defined in different ways):\n",
        "\n",
        "$$\n",
        "\\begin{eqnarray}\n",
        "\\textrm{Mean Squared Error} &=& (\\mu - \\hat{\\mu})^2 \\\\ \n",
        "\\textrm{Absolute Error} &=& \\big|\\mu - \\hat{\\mu}\\big| \\\\ \n",
        "\\textrm{Zero-One Loss} &=& \\begin{cases}\n",
        "                            0,& \\textrm{if } \\mu = \\hat{\\mu} \\\\\n",
        "                            1,              & \\textrm{otherwise}\n",
        "                            \\end{cases}\n",
        "\\end{eqnarray}\n",
        "$$\n",
        "\n",
        "?? we could have them implement these ??\n",
        "In the cell below, fill in the body of these cost functions. Each function should take one single value for $x$ (the true stimulus value : $x$) and one or more possible value estimates: $\\hat{x}$. \n",
        "\n",
        "Return an array containing the costs associated with predicting $\\hat{x}$ when the true value is $x$. Once you have written all three functions, uncomment the final line to visulize your results.\n",
        "\n",
        " _Hint:_ These functions are easy to write (1 line each!) but be sure *all* three functions return arrays of `np.float` rather than another data type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DXebTeCa9tL"
      },
      "source": [
        "# if implementing, the "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G15pqroZa9tL"
      },
      "source": [
        "### Exploring Loss functions\n",
        "\n",
        "The Mean Squared Error Loss function produces the Mean estiamte\n",
        "The Absolute Error Loss function produces the Median estiamte\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# if implementing loss; this should be re-factored; perhaps three funs and pass fun handle?\n",
        "\n",
        "def calc_loss_func(loss_f, mu_true, x):\n",
        "    error = x - mu_true\n",
        "    if loss_f == \"Mean Squared Error\":\n",
        "        loss = (error)**2\n",
        "    elif loss_f == \"Absolute Error\":\n",
        "        loss = np.abs(error)\n",
        "    elif loss_f == \"Zero-One Loss\":\n",
        "        loss = (np.abs(error) >= 0.03).astype(np.float)\n",
        "    return loss\n",
        "\n",
        "# like these from 2020 T3\n",
        "\n",
        "#@title Exercise 1\n",
        "def mse(x, x_hats):\n",
        "    \"\"\"Mean squared error (MSE) cost function\n",
        "    Args:\n",
        "      x: One true value of $x$\n",
        "      x_hats: Estimate of x\n",
        "    Returns:\n",
        "      ndarray: MSE costs associated with predicting x_hats instead of x$\n",
        "    \"\"\"\n",
        "\n",
        "    #### Remove the line below and replace it with your function \n",
        "    raise NotImplementedError(\"You need to complete this function!\")\n",
        "\n",
        "\n",
        "def abs_err(x, x_hats):\n",
        "    \"\"\"Absolute error cost function\n",
        "    Args:\n",
        "      x (scalar): One true value of $x$\n",
        "      x_hats (scalar or ndarray): Estimate of x \n",
        "    Returns:\n",
        "      ndarray (same shape as x_hats): absolute error costs associated with predicting x_hats instead of x$\n",
        "    \"\"\"\n",
        "\n",
        "    #### Remove the line below and replace it with your function \n",
        "    raise NotImplementedError(\"You need to complete this function!\")\n",
        "\n",
        "def zero_one_loss(x, x_hats):\n",
        "    \"\"\"Zero-One loss cost function\n",
        "    Args:\n",
        "      x (scalar): One true value of $x$\n",
        "      x_hats (scalar or ndarray): Estimate of x \n",
        "    Returns:\n",
        "      ndarray (same shape as x_hats): 0-1 Loss costs associated with predicting x_hats instead of x$\n",
        "    \"\"\"\n",
        "\n",
        "    #### Remove the line below and replace it with your function \n",
        "    raise NotImplementedError(\"You need to complete this function!\")\n",
        "\n",
        "# When you are done with the functions above, uncomment the line below to visualize them\n",
        "# visualize_loss_functions(mse, abs_err, zero_one_loss)\n"
      ]
    },
    {
      "source": [
        "## Exploring Loss with different distributions\n",
        "\n",
        "We can't see any differences between the Mean, median and mode with a gaussian distribution. Lets look at how the loss functions work with our mixture of gaussian distribution."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# new widget\n",
        "\n",
        "widget = interact(loss_plot_switcher,\n",
        "                  what_to_plot = widgets.Dropdown(\n",
        "                      options=[\"Gaussian\", \"Mixture of Gaussians\"], \n",
        "                      value=\"Gaussian\", description=\"Distribution: \"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfsjNwKMa9tJ"
      },
      "source": [
        "## Multiplying Gaussians - interactive demo\n",
        "\n",
        "We have implemented the multiplication of two Gaussians for you. Using the following widget, we are going to think about the information and combination of two Gaussians. It is important to remember, this isn't combining the underlying random variables! In our case, imagine we want to find the location least likely to contain the satellite or space mouse. This would be the center (average) of the two locations. Because we have uncertainty, we need to weight our uncertianty in thinking about the most likely place. Or imagine you want to know how much information is gained combining (averaging) the response of two neurons that represent locations in sensory space (think: how much information is shared by their receptive fields). In any case where we need to multiply two Gaussian distributions, we will also be weighting the information they each have about their center.\n",
        "\n",
        "Remember:\n",
        "\n",
        "$$\n",
        "\\mu_{3} = a\\mu_{1} + (1-a)\\mu_{2}\n",
        "$$\n",
        "$$\n",
        "\\sigma_{3}^{-2} = \\sigma_{1}^{-2} + \\sigma_{2}^{-2}\n",
        "$$\n",
        "\n",
        "Where:\n",
        "\n",
        "$$\n",
        "a = \\frac{\\sigma_{1}^{-2}}{\\sigma_{1}^{-2} + \\sigma_{2}^{-2}}\n",
        "$$\n",
        "\n",
        "Questions:\n",
        "\n",
        "1. What is your uncertainty (how much information) do you have about $\\mu_{3}$ with $\\mu_{1} = -1, \\mu_{2} = 1, \\sigma_{1} = \\sigma_{2} = 0.5$?\n",
        "2. What happens to your estimate of $\\mu_{3}$ as $\\sigma_{2} \\to \\infty$? (In this case, $\\sigma$ only goes to 11... but that should be loud enough.)\n",
        "3. What is the differene in your estimate of $\\mu_{3}$ if $\\sigma_{1} = \\sigma_{2} = 11$? What has changed from the first example?\n",
        "4. Set $\\mu_{1} = -4, \\mu_{2} = 4$ and change the $\\sigma$s so that $\\mu_{3}$ is close to $2$. How many $\\sigma$s will produce the same $\\mu_{3}$?\n",
        "5. Continuing, if you set $\\mu_{1} = 0$, what $\\sigma$ do you need to change so $\\mu_{3} ~= 2$?\n",
        "6. If $\\sigma_{1} = \\sigma_{2} = 0.1$, how much information do you have about the average?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUaAFKMaa9tK"
      },
      "source": [
        "widget = interact(plot_information_global,\n",
        "                  mu3 = FloatSlider(min=-6.0, max=6.0, step=0.01, value=-1.0, description=\"µ_3\", continuous_update=False),\n",
        "                  sigma3 = FloatSlider(min=0.1, max=11.0, step=0.01, value=0.5, description=\"σ_3\", continuous_update=False),\n",
        "                  mu1 = FloatSlider(min=-6.0, max=6.0, step=0.01, value=1.0, description=\"µ_1\",continuous_update=False),\n",
        "                  mu2 = FloatSlider(min=-6.0, max=6.0, step=0.01, value=1.0, description=\"µ_2\",continuous_update=False))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "interactive(children=(FloatSlider(value=-1.0, continuous_update=False, description='µ_3', max=6.0, min=-6.0, s…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1ba1416938a4375b492bcbc26034179"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeIeWJvsOnP7"
      },
      "source": [
        "## Utility functions - decisions\n",
        "\n",
        "As we saw in Tutorial 1, utility represents the gains or losses we could occur *if* we make a particular decision based on our current best knowledge. We just explored how to think about a Loss function as a utility function that tells us about the cost of making a particular estimate as a function of our error. But Ground Control needs to decide where they think Astrocat is, and Astrocat cares more about being near the space mouse and avoiding the satellite than just minimizing the LSE!\n",
        "\n",
        "Lets explore how a complex utility function effects the 'utility' for Astrocat as a function of Ground Control's estimate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkjK51i9a9tM"
      },
      "source": [
        "# simple widget\n",
        "\n",
        "widget = interact(plot_simple_utility_gaussian,\n",
        "                  mu = FloatSlider(min=-4.0, max=4.0, step=0.01, value=-0.5, description=\"µ\", continuous_update=False),\n",
        "                  sigma = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ\", continuous_update=False),\n",
        "                  mu_g = FloatSlider(min=-4.0, max=4.0, step=0.01, value=1.0, description=\"µ_gain\", continuous_update=False),\n",
        "                  mu_c = FloatSlider(min=-4.0, max=4.0, step=0.01, value=-1.0, description=\"µ_cost\", continuous_update=False),\n",
        "                  sigma_g = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_gain\", continuous_update=False),\n",
        "                  sigma_c = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_cost\", continuous_update=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0to3dQjna9tM"
      },
      "source": [
        "# Section 2: Correlation and marginalization\n",
        "\n",
        "In this section we will explore a two dimensional Gaussian, often defined as a two-dimension vector of Gaussian random variables. If the variables are independent, looking at one tells us nothing about the other. But what if the the two variables are correlated (covary)?\n",
        "\n",
        "The covariance of two Gaussians is:\n",
        "\n",
        "$$\n",
        "\\sigma_{XY} = E[(X-\\sigma_{X})(Y-\\sigma_{Y})]\n",
        "$$\n",
        "\n",
        "The correlation is the covariance normalized, so that it goes between -1 (exactly anticorrelated) to 1 (exactly correlated).\n",
        "\n",
        "$$\n",
        "\\rho_{XY} = \\frac{\\sigma_{XY}}{\\sigma_{X}\\sigma_{Y}}\n",
        "$$\n",
        "\n",
        "The these are key concepts and while we are considering two hidden states (or two random variables), they extend to $N$ dimensional vectors of Gaussian random variables. You will find these used all over computational neuroscience.\n",
        "\n",
        "Use the following widget to think about the following questions:\n",
        "\n",
        "1. If these variables represent hidden states we care about, what does observering one tell us about the other?\n",
        "2. If we wanted to measure the average of one variable while ignoring the other, how would you do it?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlxISLZCa9tN"
      },
      "source": [
        "widget = interact(plot_mvn2d,\n",
        "                  mu1 = FloatSlider(min=-1.0, max=1.0, step=0.01, value=0.0, description=\"µ_1\", continuous_update=False),\n",
        "                  mu2 = FloatSlider(min=-1.0, max=1.0, step=0.01, value=0.0, description=\"µ_2\", continuous_update=False),\n",
        "                  sigma1 = FloatSlider(min=0.1, max=1.5, step=0.01, value=0.5, description=\"σ_1\", continuous_update=False),\n",
        "                  sigma2 = FloatSlider(min=0.1, max=1.5, step=0.01, value=0.5, description=\"σ_2\", continuous_update=False),\n",
        "                  corr = FloatSlider(min=-0.99, max=0.99, step=0.01, value=0.0, description=\"ρ\", continuous_update=False))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6958VJrOnP9"
      },
      "source": [
        "## Marginalization and information\n",
        "\n",
        "We learned in Tutorial 1 that if we want to measure the probability of one or another variable, we need to average over the other. When we extend this to the correlated Gaussians we just played with, marginalization works the same way. Let's say that the two variables reflect Astrocat's position in space (in two dimensions). If we want to get our uncertainy about Astrocat's X or Y position, we need to marinalize. However, let's imagine we have a measurement from one of the variables, for example X, and we want to understand the uncertainy we have in Y. We can then calculate the conditional probability $P(Y|X=x)$. You can explore the relationship between these two concepts in the following interactive demo.\n",
        "\n",
        "But first, let's remember that we can also think about the amount of uncertainty as inversely proportional to the amount of information we have about each variable. This is important, because the joint information is determined by the correlation. For our Bayesian approach, the intuition that is important is that we can also think about the mutual information between the prior and the likelihood following a measurement.\n",
        "\n",
        "Use the following widget to think consider the following questions:\n",
        "\n",
        "1. When is the marginal distribution the same as the conditional probability distribution? Why?\n",
        "2. If $\\rho$ is large, how much information can we gain (in addition) looking at both variables vs just considering one?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xv8Y-n3Ma9tN"
      },
      "source": [
        "widget = interact(plot_marginal,\n",
        "                  sigma1 = FloatSlider(min=0.1, max=1.1, step=0.01, value=0.5, description=\"σ_1\", continuous_update=False),\n",
        "                  sigma2 = FloatSlider(min=0.1, max=1.1, step=0.01, value=0.5, description=\"σ_2\", continuous_update=False),\n",
        "                  c_x = FloatSlider(min=-1.0, max=1.0, step=0.01, value=0.0, description=\"Cx\", continuous_update=False),\n",
        "                  c_y = FloatSlider(min=-1.0, max=1.0, step=0.01, value=0.0, description=\"Cy\", continuous_update=False),\n",
        "                  corr = FloatSlider(min=-1.0, max=1.0, step=0.01, value=0.0, description=\"ρ\", continuous_update=False))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DQCv8Zma9tO"
      },
      "source": [
        "# Section 3: Bayes' theorem for continuous distributions\n",
        "\n",
        "## The Gausian example\n",
        "\n",
        "Bayes' rule tells us how to combine two sources of information: the prior (e.g., a noisy representation of Ground Control's expectations about where Astrocat is) and the likelihood (e.g., a noisy representation of the Astrocat after taking a measurement), to obtain a posterior distribution (our belief distribution) taking into account both pieces of information. Remember Bayes' rule:\n",
        "\n",
        "\\begin{eqnarray}\n",
        "\\text{Posterior} = \\frac{ \\text{Likelihood} \\times \\text{Prior}}{ \\text{Normalization constant}}\n",
        "\\end{eqnarray}\n",
        "\n",
        "When both the prior and likelihood are Gaussians, this translates into the following form:\n",
        "\n",
        "$$\n",
        "\\begin{array}{rcl}\n",
        "\\text{Likelihood} &=& \\mathcal{N}(\\mu_{likelihood},\\sigma_{likelihood}^2) \\\\\n",
        "\\text{Prior} &=& \\mathcal{N}(\\mu_{prior},\\sigma_{prior}^2) \\\\\n",
        "\\text{Posterior} &=& \\mathcal{N}\\left( \\frac{\\sigma^2_{likelihood}\\mu_{prior}+\\sigma^2_{prior}\\mu_{likelihood}}{\\sigma^2_{likelihood}+\\sigma^2_{prior}}, \\frac{\\sigma^2_{likelihood}\\sigma^2_{prior}}{\\sigma^2_{likelihood}+\\sigma^2_{prior}} \\right) \\\\\n",
        "&\\propto& \\mathcal{N}(\\mu_{likelihood},\\sigma_{likelihood}^2) \\times \\mathcal{N}(\\mu_{prior},\\sigma_{prior}^2)\n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "In these equations, $\\mathcal{N}(\\mu,\\sigma^2)$ denotes a Gaussian distribution with parameters $\\mu$ and $\\sigma^2$:\n",
        "$$\n",
        "\\mathcal{N}(\\mu, \\sigma) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\; \\exp \\bigg( \\frac{-(x-\\mu)^2}{2\\sigma^2} \\bigg)\n",
        "$$\n",
        "\n",
        "Let's consider the following questions using the following interactive demo:\n",
        "\n",
        "1. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18XfQvk2a9tO"
      },
      "source": [
        "widget = interact(plot_bayes,\n",
        "                  mu1 = FloatSlider(min=-4.0, max=4.0, step=0.01, value=-0.5, description=\"µ_prior\", continuous_update=False),\n",
        "                  mu2 = FloatSlider(min=-4.0, max=4.0, step=0.01, value=0.5, description=\"µ_likelihood\", continuous_update=False),\n",
        "                  sigma1 = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_prior\", continuous_update=False),\n",
        "                  sigma2 = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_likelihood\", continuous_update=False))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "interactive(children=(FloatSlider(value=-0.5, continuous_update=False, description='µ_prior', max=4.0, min=-4.…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95355e15480a46f5b323cd0100be0f55"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDuI85NOa9tP"
      },
      "source": [
        "## Exploring priors\n",
        "\n",
        "What would happen if we had a different prior distribution for Astrocat's location? Bayes' Rule works exactly the same way if our prior is not a Guassian (though the analytical solution may be far more complex or impossible). Let's look at how the posterior behaves if we have a different prior over Astrocat's location.\n",
        "\n",
        "Consider the following questions:\n",
        "\n",
        "1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlnOtfSva9tS"
      },
      "source": [
        "widget = interact(plot_prior_switcher,\n",
        "                  what_to_plot = widgets.Dropdown(\n",
        "                      options=[\"Gaussian\", \"Mixture of Gaussians\", \"Uniform\", \"Gamma\"], \n",
        "                      value=\"Gaussian\", description=\"Prior: \"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToCxtWwha9tT"
      },
      "source": [
        "# Section 4: Bayesian decisions\n",
        "\n",
        "## Bayesian estimation on the posterior\n",
        "\n",
        " - Loss with non-gaussian priors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "widget = interact(plot_bayes_loss_utility_switcher,\n",
        "                  what_to_plot = widgets.Dropdown(\n",
        "                      options=[\"Gaussian\", \"Mixture of Gaussians\", \"Uniform\", \"Gamma\"], \n",
        "                      value=\"Gaussian\", description=\"Prior: \"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpOhf8aia9tM"
      },
      "source": [
        "## Bayesian decisions\n",
        "\n",
        "- A complex utility function is often necessary to describe realworld situations\n",
        "- let's see how different complex utility functions interact with compelex posteriors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNo6jiJqa9tU"
      },
      "source": [
        "widget = interact(plot_utility_gaussian,\n",
        "                  mu1 = FloatSlider(min=-4.0, max=4.0, step=0.01, value=-0.5, description=\"µ_prior\", continuous_update=False),\n",
        "                  mu2 = FloatSlider(min=-4.0, max=4.0, step=0.01, value=0.5, description=\"µ_likelihood\", continuous_update=False),\n",
        "                  sigma1 = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_prior\", continuous_update=False),\n",
        "                  sigma2 = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_likelihood\", continuous_update=False),\n",
        "                  mu_g = FloatSlider(min=-4.0, max=4.0, step=0.01, value=1.0, description=\"µ_gain\", continuous_update=False),\n",
        "                  mu_c = FloatSlider(min=-4.0, max=4.0, step=0.01, value=-1.0, description=\"µ_cost\", continuous_update=False),\n",
        "                  sigma_g = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_gain\", continuous_update=False),\n",
        "                  sigma_c = FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description=\"σ_cost\", continuous_update=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "uiKmKaJua9tU"
      },
      "source": [
        "#@title Video 3: Outro\n",
        "video = YouTubeVideo(id='UgeAtE8xZT8', width=854, height=480, fs=1)\n",
        "print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U19yZlWXa9tU"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qnVR5uQa9tU"
      },
      "source": [
        "In this tutorial, we ..."
      ]
    }
  ]
}